/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 15:53:42,296 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_155342-ayu9b6qq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_M10 | zs | 2025-07-12-15-53-38 | bioclip2 | full_text_head | 2025-07-12-15-53-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/ayu9b6qq
2025-07-12 15:53:43,234 - root - INFO - wandb logging is enabled.
2025-07-12 15:53:43,235 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_M10_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_M10/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_M10/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_M10/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_M10/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 15:53:43,238 - root - INFO - Using Bioclip-2 model. 
2025-07-12 15:53:43,238 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 15:53:45,185 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 15:53:47,770 - root - INFO - Pretraining classifier... 
2025-07-12 15:53:47,781 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 15:53:47,803 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 15:53:47,803 - root - INFO - Subset length: 1131
2025-07-12 15:53:47,804 - root - INFO - Pretrain dataset size: 1131. 
2025-07-12 15:54:02,639 - root - INFO - Epoch 0, loss: 2.3267, acc: 0.8462, lr: 0.00002500. 
2025-07-12 15:54:17,240 - root - INFO - Epoch 1, loss: 2.2143, acc: 0.9620, lr: 0.00002494. 
2025-07-12 15:54:31,883 - root - INFO - Epoch 2, loss: 2.1808, acc: 0.9779, lr: 0.00002475. 
2025-07-12 15:54:46,540 - root - INFO - Epoch 3, loss: 2.1656, acc: 0.9637, lr: 0.00002445. 
2025-07-12 15:55:01,234 - root - INFO - Epoch 4, loss: 2.1355, acc: 0.9832, lr: 0.00002403. 
2025-07-12 15:55:15,879 - root - INFO - Epoch 5, loss: 2.1074, acc: 0.9965, lr: 0.00002349. 
2025-07-12 15:55:30,585 - root - INFO - Epoch 6, loss: 2.0852, acc: 0.9965, lr: 0.00002285. 
2025-07-12 15:55:45,188 - root - INFO - Epoch 7, loss: 2.0646, acc: 0.9991, lr: 0.00002211. 
2025-07-12 15:55:59,821 - root - INFO - Epoch 8, loss: 2.0441, acc: 1.0000, lr: 0.00002128. 
2025-07-12 15:56:14,466 - root - INFO - Epoch 9, loss: 2.0252, acc: 1.0000, lr: 0.00002036. 
2025-07-12 15:56:29,180 - root - INFO - Epoch 10, loss: 2.0071, acc: 1.0000, lr: 0.00001937. 
2025-07-12 15:56:43,806 - root - INFO - Epoch 11, loss: 1.9896, acc: 1.0000, lr: 0.00001833. 
2025-07-12 15:56:58,453 - root - INFO - Epoch 12, loss: 1.9732, acc: 1.0000, lr: 0.00001723. 
2025-07-12 15:57:13,194 - root - INFO - Epoch 13, loss: 1.9583, acc: 1.0000, lr: 0.00001609. 
2025-07-12 15:57:27,905 - root - INFO - Epoch 14, loss: 1.9438, acc: 1.0000, lr: 0.00001493. 
2025-07-12 15:57:42,463 - root - INFO - Epoch 15, loss: 1.9306, acc: 1.0000, lr: 0.00001375. 
2025-07-12 15:57:57,111 - root - INFO - Epoch 16, loss: 1.9190, acc: 1.0000, lr: 0.00001257. 
2025-07-12 15:58:11,853 - root - INFO - Epoch 17, loss: 1.9080, acc: 1.0000, lr: 0.00001141. 
2025-07-12 15:58:26,639 - root - INFO - Epoch 18, loss: 1.8981, acc: 1.0000, lr: 0.00001027. 
2025-07-12 15:58:41,285 - root - INFO - Epoch 19, loss: 1.8898, acc: 1.0000, lr: 0.00000917. 
2025-07-12 15:58:55,961 - root - INFO - Epoch 20, loss: 1.8818, acc: 1.0000, lr: 0.00000813. 
2025-07-12 15:59:10,685 - root - INFO - Epoch 21, loss: 1.8742, acc: 1.0000, lr: 0.00000714. 
2025-07-12 15:59:25,371 - root - INFO - Epoch 22, loss: 1.8689, acc: 1.0000, lr: 0.00000622. 
2025-07-12 15:59:40,051 - root - INFO - Epoch 23, loss: 1.8631, acc: 1.0000, lr: 0.00000539. 
2025-07-12 15:59:54,664 - root - INFO - Epoch 24, loss: 1.8585, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:00:09,415 - root - INFO - Epoch 25, loss: 1.8549, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:00:23,990 - root - INFO - Epoch 26, loss: 1.8511, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:00:38,607 - root - INFO - Epoch 27, loss: 1.8487, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:00:53,289 - root - INFO - Epoch 28, loss: 1.8458, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:01:07,885 - root - INFO - Epoch 29, loss: 1.8432, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:01:22,626 - root - INFO - Epoch 30, loss: 1.8414, acc: 1.0000, lr: 0.00000250. 
2025-07-12 16:01:37,288 - root - INFO - Epoch 31, loss: 1.8393, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:01:51,906 - root - INFO - Epoch 32, loss: 1.8369, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:02:06,477 - root - INFO - Epoch 33, loss: 1.8338, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:02:21,221 - root - INFO - Epoch 34, loss: 1.8315, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:02:36,227 - root - INFO - Epoch 35, loss: 1.8273, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:02:50,903 - root - INFO - Epoch 36, loss: 1.8238, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:03:05,547 - root - INFO - Epoch 37, loss: 1.8187, acc: 1.0000, lr: 0.00000539. 
2025-07-12 16:03:20,189 - root - INFO - Epoch 38, loss: 1.8139, acc: 1.0000, lr: 0.00000622. 
2025-07-12 16:03:34,842 - root - INFO - Epoch 39, loss: 1.8082, acc: 1.0000, lr: 0.00000714. 
2025-07-12 16:03:49,526 - root - INFO - Epoch 40, loss: 1.8013, acc: 1.0000, lr: 0.00000813. 
2025-07-12 16:04:04,237 - root - INFO - Epoch 41, loss: 1.7935, acc: 1.0000, lr: 0.00000917. 
2025-07-12 16:04:18,783 - root - INFO - Epoch 42, loss: 1.7857, acc: 1.0000, lr: 0.00001027. 
2025-07-12 16:04:33,473 - root - INFO - Epoch 43, loss: 1.7763, acc: 1.0000, lr: 0.00001141. 
2025-07-12 16:04:48,094 - root - INFO - Epoch 44, loss: 1.7650, acc: 1.0000, lr: 0.00001257. 
2025-07-12 16:05:02,726 - root - INFO - Epoch 45, loss: 1.7535, acc: 1.0000, lr: 0.00001375. 
2025-07-12 16:05:17,311 - root - INFO - Epoch 46, loss: 1.7425, acc: 1.0000, lr: 0.00001493. 
2025-07-12 16:05:31,995 - root - INFO - Epoch 47, loss: 1.7282, acc: 1.0000, lr: 0.00001609. 
2025-07-12 16:05:46,679 - root - INFO - Epoch 48, loss: 1.7124, acc: 1.0000, lr: 0.00001723. 
2025-07-12 16:06:01,317 - root - INFO - Epoch 49, loss: 1.6991, acc: 1.0000, lr: 0.00001833. 
2025-07-12 16:06:15,948 - root - INFO - Epoch 50, loss: 1.6817, acc: 1.0000, lr: 0.00001938. 
2025-07-12 16:06:30,625 - root - INFO - Epoch 51, loss: 1.6634, acc: 1.0000, lr: 0.00002036. 
2025-07-12 16:06:45,269 - root - INFO - Epoch 52, loss: 1.6459, acc: 1.0000, lr: 0.00002128. 
2025-07-12 16:06:59,956 - root - INFO - Epoch 53, loss: 1.6279, acc: 1.0000, lr: 0.00002211. 
2025-07-12 16:07:14,542 - root - INFO - Epoch 54, loss: 1.6102, acc: 1.0000, lr: 0.00002285. 
2025-07-12 16:07:29,119 - root - INFO - Epoch 55, loss: 1.5893, acc: 1.0000, lr: 0.00002349. 
2025-07-12 16:07:43,849 - root - INFO - Epoch 56, loss: 1.5703, acc: 1.0000, lr: 0.00002403. 
2025-07-12 16:07:58,551 - root - INFO - Epoch 57, loss: 1.5486, acc: 1.0000, lr: 0.00002445. 
2025-07-12 16:08:13,339 - root - INFO - Epoch 58, loss: 1.5287, acc: 1.0000, lr: 0.00002475. 
2025-07-12 16:08:28,011 - root - INFO - Epoch 59, loss: 1.5073, acc: 1.0000, lr: 0.00002494. 
2025-07-12 16:08:28,029 - root - INFO - Checkpoint list, length: 8: 
2025-07-12 16:08:28,029 - root - INFO - 	ckp_1 
2025-07-12 16:08:28,029 - root - INFO - 	ckp_2 
2025-07-12 16:08:28,029 - root - INFO - 	ckp_3 
2025-07-12 16:08:28,030 - root - INFO - 	ckp_4 
2025-07-12 16:08:28,030 - root - INFO - 	ckp_5 
2025-07-12 16:08:28,030 - root - INFO - 	ckp_6 
2025-07-12 16:08:28,030 - root - INFO - 	ckp_7 
2025-07-12 16:08:28,030 - root - INFO - 	ckp_8 
2025-07-12 16:08:28,043 - root - INFO - Training on checkpoint ckp_1. 
2025-07-12 16:08:28,043 - root - INFO - Subset length: 0
2025-07-12 16:08:28,043 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:08:28,044 - root - INFO - Subset length: 66
2025-07-12 16:08:28,044 - root - INFO - Training dataset size: 0. 
2025-07-12 16:08:28,044 - root - INFO - Evaluation dataset size: 66. 
2025-07-12 16:08:28,045 - root - INFO - OOD mask: 0 / 0. 
2025-07-12 16:08:28,045 - root - INFO - AL mask: 0 / 0. 
2025-07-12 16:08:28,045 - root - INFO - Evaluating on next checkpoint ckp_1. 
2025-07-12 16:08:29,083 - root - INFO - Number of samples: 66, acc: 0.6818, balanced acc: 0.6556, loss: 1.9838. 
2025-07-12 16:08:29,084 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:29,089 - root - INFO - Training on checkpoint ckp_2. 
2025-07-12 16:08:29,089 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:08:29,091 - root - INFO - Subset length: 105
2025-07-12 16:08:29,091 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:08:29,092 - root - INFO - Subset length: 23
2025-07-12 16:08:29,092 - root - INFO - Training dataset size: 105. 
2025-07-12 16:08:29,092 - root - INFO - Evaluation dataset size: 23. 
2025-07-12 16:08:29,092 - root - INFO - OOD mask: 0 / 105. 
2025-07-12 16:08:29,092 - root - INFO - AL mask: 0 / 105. 
2025-07-12 16:08:29,092 - root - INFO - Evaluating on current checkpoint ckp_1. 
2025-07-12 16:08:29,092 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:08:29,094 - root - INFO - Subset length: 66
2025-07-12 16:08:29,681 - root - INFO - Eval on current training checkpoint ckp_1: Number of samples: 66, acc: 0.6818, balanced acc: 0.6556, loss: 1.9838. 
2025-07-12 16:08:29,681 - root - INFO - Evaluating on next checkpoint ckp_2. 
2025-07-12 16:08:30,049 - root - INFO - Number of samples: 23, acc: 0.9565, balanced acc: 0.9545, loss: 1.5510. 
2025-07-12 16:08:30,050 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:30,051 - root - INFO - Training on checkpoint ckp_3. 
2025-07-12 16:08:30,052 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:08:30,057 - root - INFO - Subset length: 251
2025-07-12 16:08:30,058 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:08:30,059 - root - INFO - Subset length: 64
2025-07-12 16:08:30,059 - root - INFO - Training dataset size: 251. 
2025-07-12 16:08:30,059 - root - INFO - Evaluation dataset size: 64. 
2025-07-12 16:08:30,059 - root - INFO - OOD mask: 0 / 251. 
2025-07-12 16:08:30,059 - root - INFO - AL mask: 0 / 251. 
2025-07-12 16:08:30,059 - root - INFO - Evaluating on current checkpoint ckp_2. 
2025-07-12 16:08:30,060 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:08:30,060 - root - INFO - Subset length: 23
2025-07-12 16:08:30,272 - root - INFO - Eval on current training checkpoint ckp_2: Number of samples: 23, acc: 0.9565, balanced acc: 0.9545, loss: 1.5510. 
2025-07-12 16:08:30,273 - root - INFO - Evaluating on next checkpoint ckp_3. 
2025-07-12 16:08:31,506 - root - INFO - Number of samples: 64, acc: 0.7344, balanced acc: 0.7447, loss: 2.0229. 
2025-07-12 16:08:31,507 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:31,508 - root - INFO - Training on checkpoint ckp_4. 
2025-07-12 16:08:31,508 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:08:31,511 - root - INFO - Subset length: 99
2025-07-12 16:08:31,511 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:08:31,512 - root - INFO - Subset length: 67
2025-07-12 16:08:31,513 - root - INFO - Training dataset size: 99. 
2025-07-12 16:08:31,513 - root - INFO - Evaluation dataset size: 67. 
2025-07-12 16:08:31,513 - root - INFO - OOD mask: 0 / 99. 
2025-07-12 16:08:31,513 - root - INFO - AL mask: 0 / 99. 
2025-07-12 16:08:31,513 - root - INFO - Evaluating on current checkpoint ckp_3. 
2025-07-12 16:08:31,513 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:08:31,514 - root - INFO - Subset length: 64
2025-07-12 16:08:32,183 - root - INFO - Eval on current training checkpoint ckp_3: Number of samples: 64, acc: 0.7344, balanced acc: 0.7447, loss: 2.0229. 
2025-07-12 16:08:32,183 - root - INFO - Evaluating on next checkpoint ckp_4. 
2025-07-12 16:08:33,495 - root - INFO - Number of samples: 67, acc: 0.7015, balanced acc: 0.7222, loss: 1.9284. 
2025-07-12 16:08:33,496 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:33,497 - root - INFO - Training on checkpoint ckp_5. 
2025-07-12 16:08:33,497 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:08:33,500 - root - INFO - Subset length: 105
2025-07-12 16:08:33,500 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:08:33,501 - root - INFO - Subset length: 56
2025-07-12 16:08:33,501 - root - INFO - Training dataset size: 105. 
2025-07-12 16:08:33,501 - root - INFO - Evaluation dataset size: 56. 
2025-07-12 16:08:33,501 - root - INFO - OOD mask: 0 / 105. 
2025-07-12 16:08:33,501 - root - INFO - AL mask: 0 / 105. 
2025-07-12 16:08:33,502 - root - INFO - Evaluating on current checkpoint ckp_4. 
2025-07-12 16:08:33,502 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:08:33,503 - root - INFO - Subset length: 67
2025-07-12 16:08:34,215 - root - INFO - Eval on current training checkpoint ckp_4: Number of samples: 67, acc: 0.7015, balanced acc: 0.7222, loss: 1.9284. 
2025-07-12 16:08:34,216 - root - INFO - Evaluating on next checkpoint ckp_5. 
2025-07-12 16:08:35,340 - root - INFO - Number of samples: 56, acc: 0.7857, balanced acc: 0.7636, loss: 1.8874. 
2025-07-12 16:08:35,340 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:35,342 - root - INFO - Training on checkpoint ckp_6. 
2025-07-12 16:08:35,342 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:08:35,345 - root - INFO - Subset length: 122
2025-07-12 16:08:35,345 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:08:35,346 - root - INFO - Subset length: 32
2025-07-12 16:08:35,346 - root - INFO - Training dataset size: 122. 
2025-07-12 16:08:35,346 - root - INFO - Evaluation dataset size: 32. 
2025-07-12 16:08:35,346 - root - INFO - OOD mask: 0 / 122. 
2025-07-12 16:08:35,346 - root - INFO - AL mask: 0 / 122. 
2025-07-12 16:08:35,346 - root - INFO - Evaluating on current checkpoint ckp_5. 
2025-07-12 16:08:35,346 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:08:35,347 - root - INFO - Subset length: 56
2025-07-12 16:08:35,942 - root - INFO - Eval on current training checkpoint ckp_5: Number of samples: 56, acc: 0.7857, balanced acc: 0.7636, loss: 1.8874. 
2025-07-12 16:08:35,942 - root - INFO - Evaluating on next checkpoint ckp_6. 
2025-07-12 16:08:36,685 - root - INFO - Number of samples: 32, acc: 0.9375, balanced acc: 0.9333, loss: 1.5523. 
2025-07-12 16:08:36,686 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:36,687 - root - INFO - Training on checkpoint ckp_7. 
2025-07-12 16:08:36,687 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:08:36,691 - root - INFO - Subset length: 136
2025-07-12 16:08:36,691 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:08:36,692 - root - INFO - Subset length: 31
2025-07-12 16:08:36,692 - root - INFO - Training dataset size: 136. 
2025-07-12 16:08:36,692 - root - INFO - Evaluation dataset size: 31. 
2025-07-12 16:08:36,692 - root - INFO - OOD mask: 0 / 136. 
2025-07-12 16:08:36,692 - root - INFO - AL mask: 0 / 136. 
2025-07-12 16:08:36,692 - root - INFO - Evaluating on current checkpoint ckp_6. 
2025-07-12 16:08:36,692 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:08:36,693 - root - INFO - Subset length: 32
2025-07-12 16:08:37,057 - root - INFO - Eval on current training checkpoint ckp_6: Number of samples: 32, acc: 0.9375, balanced acc: 0.9333, loss: 1.5523. 
2025-07-12 16:08:37,057 - root - INFO - Evaluating on next checkpoint ckp_7. 
2025-07-12 16:08:37,387 - root - INFO - Number of samples: 31, acc: 1.0000, balanced acc: 1.0000, loss: 1.5029. 
2025-07-12 16:08:37,387 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
2025-07-12 16:08:37,389 - root - INFO - Training on checkpoint ckp_8. 
2025-07-12 16:08:37,389 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:08:37,392 - root - INFO - Subset length: 136
2025-07-12 16:08:37,392 - root - INFO - Gathering samples from checkpoints: ['ckp_8']
2025-07-12 16:08:37,393 - root - INFO - Subset length: 67
2025-07-12 16:08:37,394 - root - INFO - Training dataset size: 136. 
2025-07-12 16:08:37,394 - root - INFO - Evaluation dataset size: 67. 
2025-07-12 16:08:37,394 - root - INFO - OOD mask: 0 / 136. 
2025-07-12 16:08:37,394 - root - INFO - AL mask: 0 / 136. 
2025-07-12 16:08:37,394 - root - INFO - Evaluating on current checkpoint ckp_7. 
2025-07-12 16:08:37,394 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:08:37,395 - root - INFO - Subset length: 31
2025-07-12 16:08:37,601 - root - INFO - Eval on current training checkpoint ckp_7: Number of samples: 31, acc: 1.0000, balanced acc: 1.0000, loss: 1.5029. 
2025-07-12 16:08:37,601 - root - INFO - Evaluating on next checkpoint ckp_8. 
2025-07-12 16:08:38,909 - root - INFO - Number of samples: 67, acc: 0.5672, balanced acc: 0.5806, loss: 2.0139. 
2025-07-12 16:08:38,910 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_M10/zs/2025-07-12-15-53-38/bioclip2/full_text_head/2025-07-12-15-53-42/log. 
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          accuracy ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÅ
wandb: balanced_accuracy ‚ñÇ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÅ
wandb: 
wandb: Run summary:
wandb:          accuracy 0.56716
wandb: balanced_accuracy 0.58056
wandb: 
wandb: üöÄ View run serengeti_serengeti_M10 | zs | 2025-07-12-15-53-38 | bioclip2 | full_text_head | 2025-07-12-15-53-42 at: https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/ayu9b6qq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250712_155342-ayu9b6qq/logs
2025-07-12 16:08:39,519 - root - INFO - Elapsed time: 897.22 seconds. 
/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 16:08:46,617 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_C11/zs/2025-07-12-16-08-41/bioclip2/full_text_head/2025-07-12-16-08-46/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_160846-4q1rm56n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_C11 | zs | 2025-07-12-16-08-41 | bioclip2 | full_text_head | 2025-07-12-16-08-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/4q1rm56n
2025-07-12 16:08:47,623 - root - INFO - wandb logging is enabled.
2025-07-12 16:08:47,623 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_C11_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C11/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C11/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C11/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_C11/zs/2025-07-12-16-08-41/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C11/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_C11/zs/2025-07-12-16-08-41/bioclip2/full_text_head/2025-07-12-16-08-46/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 16:08:47,642 - root - INFO - Using Bioclip-2 model. 
2025-07-12 16:08:47,642 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 16:08:49,564 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 16:08:52,452 - root - INFO - Pretraining classifier... 
2025-07-12 16:08:52,502 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 16:08:52,784 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 16:08:52,784 - root - INFO - Subset length: 7183
2025-07-12 16:08:52,787 - root - INFO - Pretrain dataset size: 7183. 
2025-07-12 16:10:22,963 - root - INFO - Epoch 0, loss: 2.3117, acc: 0.9632, lr: 0.00002500. 
2025-07-12 16:11:52,784 - root - INFO - Epoch 1, loss: 2.1364, acc: 0.9719, lr: 0.00002494. 
2025-07-12 16:13:22,684 - root - INFO - Epoch 2, loss: 1.9682, acc: 0.9781, lr: 0.00002475. 
2025-07-12 16:14:52,673 - root - INFO - Epoch 3, loss: 1.8069, acc: 0.9809, lr: 0.00002445. 
