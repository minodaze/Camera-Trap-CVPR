/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 15:53:32,275 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_155332-hh14rbkw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_Q04 | upper_bound | 2025-07-12-15-53-20 | bioclip2 | full_text_head | 2025-07-12-15-53-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/hh14rbkw
2025-07-12 15:53:33,333 - root - INFO - wandb logging is enabled.
2025-07-12 15:53:33,334 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_Q04_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_Q04/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_Q04/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_Q04/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_Q04/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 15:53:33,344 - root - INFO - Using Bioclip-2 model. 
2025-07-12 15:53:33,344 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 15:53:35,267 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 15:53:41,163 - root - INFO - Pretraining classifier... 
2025-07-12 15:53:41,178 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 15:53:41,210 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 15:53:41,210 - root - INFO - Subset length: 1703
2025-07-12 15:53:41,211 - root - INFO - Pretrain dataset size: 1703. 
2025-07-12 15:54:03,612 - root - INFO - Epoch 0, loss: 2.0804, acc: 0.8990, lr: 0.00002500. 
2025-07-12 15:54:25,548 - root - INFO - Epoch 1, loss: 1.9865, acc: 0.9759, lr: 0.00002494. 
2025-07-12 15:54:47,482 - root - INFO - Epoch 2, loss: 1.9480, acc: 0.9847, lr: 0.00002475. 
2025-07-12 15:55:09,399 - root - INFO - Epoch 3, loss: 1.9210, acc: 0.9800, lr: 0.00002445. 
2025-07-12 15:55:31,362 - root - INFO - Epoch 4, loss: 1.8860, acc: 0.9912, lr: 0.00002403. 
2025-07-12 15:55:53,409 - root - INFO - Epoch 5, loss: 1.8639, acc: 0.9748, lr: 0.00002349. 
2025-07-12 15:56:15,358 - root - INFO - Epoch 6, loss: 1.8339, acc: 0.9771, lr: 0.00002285. 
2025-07-12 15:56:37,141 - root - INFO - Epoch 7, loss: 1.8043, acc: 0.9812, lr: 0.00002211. 
2025-07-12 15:56:58,937 - root - INFO - Epoch 8, loss: 1.7714, acc: 0.9924, lr: 0.00002128. 
2025-07-12 15:57:20,918 - root - INFO - Epoch 9, loss: 1.7412, acc: 0.9982, lr: 0.00002036. 
2025-07-12 15:57:42,880 - root - INFO - Epoch 10, loss: 1.7195, acc: 0.9935, lr: 0.00001937. 
2025-07-12 15:58:04,687 - root - INFO - Epoch 11, loss: 1.6967, acc: 0.9894, lr: 0.00001833. 
2025-07-12 15:58:26,586 - root - INFO - Epoch 12, loss: 1.6701, acc: 0.9977, lr: 0.00001723. 
2025-07-12 15:58:48,510 - root - INFO - Epoch 13, loss: 1.6498, acc: 0.9941, lr: 0.00001609. 
2025-07-12 15:59:10,491 - root - INFO - Epoch 14, loss: 1.6290, acc: 0.9994, lr: 0.00001493. 
2025-07-12 15:59:32,422 - root - INFO - Epoch 15, loss: 1.6110, acc: 0.9994, lr: 0.00001375. 
2025-07-12 15:59:54,404 - root - INFO - Epoch 16, loss: 1.5945, acc: 0.9994, lr: 0.00001257. 
2025-07-12 16:00:16,298 - root - INFO - Epoch 17, loss: 1.5788, acc: 0.9982, lr: 0.00001141. 
2025-07-12 16:00:38,241 - root - INFO - Epoch 18, loss: 1.5657, acc: 0.9994, lr: 0.00001027. 
2025-07-12 16:01:00,178 - root - INFO - Epoch 19, loss: 1.5537, acc: 0.9994, lr: 0.00000917. 
2025-07-12 16:01:22,077 - root - INFO - Epoch 20, loss: 1.5432, acc: 0.9994, lr: 0.00000813. 
2025-07-12 16:01:43,992 - root - INFO - Epoch 21, loss: 1.5324, acc: 0.9994, lr: 0.00000714. 
2025-07-12 16:02:05,968 - root - INFO - Epoch 22, loss: 1.5252, acc: 0.9994, lr: 0.00000622. 
2025-07-12 16:02:27,924 - root - INFO - Epoch 23, loss: 1.5182, acc: 0.9994, lr: 0.00000539. 
2025-07-12 16:02:49,818 - root - INFO - Epoch 24, loss: 1.5128, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:03:11,823 - root - INFO - Epoch 25, loss: 1.5067, acc: 0.9994, lr: 0.00000401. 
2025-07-12 16:03:33,611 - root - INFO - Epoch 26, loss: 1.5019, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:03:55,597 - root - INFO - Epoch 27, loss: 1.4973, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:04:17,462 - root - INFO - Epoch 28, loss: 1.4954, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:04:39,426 - root - INFO - Epoch 29, loss: 1.4931, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:05:01,389 - root - INFO - Epoch 30, loss: 1.4889, acc: 1.0000, lr: 0.00000250. 
2025-07-12 16:05:23,423 - root - INFO - Epoch 31, loss: 1.4853, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:05:45,505 - root - INFO - Epoch 32, loss: 1.4836, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:06:07,326 - root - INFO - Epoch 33, loss: 1.4806, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:06:29,311 - root - INFO - Epoch 34, loss: 1.4741, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:06:51,217 - root - INFO - Epoch 35, loss: 1.4709, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:07:13,201 - root - INFO - Epoch 36, loss: 1.4664, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:07:35,089 - root - INFO - Epoch 37, loss: 1.4588, acc: 1.0000, lr: 0.00000539. 
2025-07-12 16:07:57,084 - root - INFO - Epoch 38, loss: 1.4536, acc: 1.0000, lr: 0.00000622. 
2025-07-12 16:08:18,987 - root - INFO - Epoch 39, loss: 1.4464, acc: 1.0000, lr: 0.00000714. 
2025-07-12 16:08:40,849 - root - INFO - Epoch 40, loss: 1.4371, acc: 1.0000, lr: 0.00000813. 
2025-07-12 16:09:02,727 - root - INFO - Epoch 41, loss: 1.4263, acc: 1.0000, lr: 0.00000917. 
2025-07-12 16:09:24,609 - root - INFO - Epoch 42, loss: 1.4139, acc: 1.0000, lr: 0.00001027. 
2025-07-12 16:09:46,530 - root - INFO - Epoch 43, loss: 1.4036, acc: 1.0000, lr: 0.00001141. 
2025-07-12 16:10:08,480 - root - INFO - Epoch 44, loss: 1.3904, acc: 1.0000, lr: 0.00001257. 
2025-07-12 16:10:30,466 - root - INFO - Epoch 45, loss: 1.3738, acc: 1.0000, lr: 0.00001375. 
2025-07-12 16:10:52,318 - root - INFO - Epoch 46, loss: 1.3568, acc: 1.0000, lr: 0.00001493. 
2025-07-12 16:11:14,136 - root - INFO - Epoch 47, loss: 1.3403, acc: 1.0000, lr: 0.00001609. 
2025-07-12 16:11:35,925 - root - INFO - Epoch 48, loss: 1.3229, acc: 1.0000, lr: 0.00001723. 
2025-07-12 16:11:57,854 - root - INFO - Epoch 49, loss: 1.3038, acc: 1.0000, lr: 0.00001833. 
2025-07-12 16:12:19,824 - root - INFO - Epoch 50, loss: 1.2852, acc: 1.0000, lr: 0.00001938. 
2025-07-12 16:12:41,726 - root - INFO - Epoch 51, loss: 1.2642, acc: 1.0000, lr: 0.00002036. 
2025-07-12 16:13:03,677 - root - INFO - Epoch 52, loss: 1.2391, acc: 1.0000, lr: 0.00002128. 
2025-07-12 16:13:25,582 - root - INFO - Epoch 53, loss: 1.2193, acc: 1.0000, lr: 0.00002211. 
2025-07-12 16:13:47,584 - root - INFO - Epoch 54, loss: 1.1961, acc: 1.0000, lr: 0.00002285. 
2025-07-12 16:14:09,383 - root - INFO - Epoch 55, loss: 1.1704, acc: 1.0000, lr: 0.00002349. 
2025-07-12 16:14:31,398 - root - INFO - Epoch 56, loss: 1.1515, acc: 1.0000, lr: 0.00002403. 
2025-07-12 16:14:53,151 - root - INFO - Epoch 57, loss: 1.1259, acc: 1.0000, lr: 0.00002445. 
2025-07-12 16:15:15,211 - root - INFO - Epoch 58, loss: 1.1039, acc: 1.0000, lr: 0.00002475. 
2025-07-12 16:15:37,017 - root - INFO - Epoch 59, loss: 1.0819, acc: 1.0000, lr: 0.00002494. 
2025-07-12 16:15:37,039 - root - INFO - Checkpoint list, length: 8: 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_1 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_2 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_3 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_4 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_5 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_6 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_7 
2025-07-12 16:15:37,040 - root - INFO - 	ckp_8 
2025-07-12 16:15:37,053 - root - INFO - Training on checkpoint ckp_1. 
2025-07-12 16:15:37,053 - root - INFO - Subset length: 0
2025-07-12 16:15:37,053 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:15:37,054 - root - INFO - Subset length: 55
2025-07-12 16:15:37,054 - root - INFO - Training dataset size: 0. 
2025-07-12 16:15:37,054 - root - INFO - Evaluation dataset size: 55. 
2025-07-12 16:15:37,054 - root - INFO - OOD mask: 0 / 0. 
2025-07-12 16:15:37,055 - root - INFO - AL mask: 0 / 0. 
2025-07-12 16:15:37,055 - root - INFO - Evaluating on next checkpoint ckp_1. 
2025-07-12 16:15:38,069 - root - INFO - Number of samples: 55, acc: 0.9818, balanced acc: 0.9818, loss: 1.4728. 
2025-07-12 16:15:38,070 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:38,079 - root - INFO - Training on checkpoint ckp_2. 
2025-07-12 16:15:38,079 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:15:38,082 - root - INFO - Subset length: 118
2025-07-12 16:15:38,082 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:15:38,083 - root - INFO - Subset length: 46
2025-07-12 16:15:38,083 - root - INFO - Training dataset size: 118. 
2025-07-12 16:15:38,083 - root - INFO - Evaluation dataset size: 46. 
2025-07-12 16:15:38,083 - root - INFO - OOD mask: 0 / 118. 
2025-07-12 16:15:38,083 - root - INFO - AL mask: 0 / 118. 
2025-07-12 16:15:38,083 - root - INFO - Evaluating on current checkpoint ckp_1. 
2025-07-12 16:15:38,084 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:15:38,085 - root - INFO - Subset length: 55
2025-07-12 16:15:38,644 - root - INFO - Eval on current training checkpoint ckp_1: Number of samples: 55, acc: 0.9818, balanced acc: 0.9818, loss: 1.4728. 
2025-07-12 16:15:38,644 - root - INFO - Evaluating on next checkpoint ckp_2. 
2025-07-12 16:15:39,389 - root - INFO - Number of samples: 46, acc: 1.0000, balanced acc: 1.0000, loss: 1.0610. 
2025-07-12 16:15:39,390 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:39,391 - root - INFO - Training on checkpoint ckp_3. 
2025-07-12 16:15:39,391 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:15:39,399 - root - INFO - Subset length: 340
2025-07-12 16:15:39,399 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:15:39,401 - root - INFO - Subset length: 76
2025-07-12 16:15:39,401 - root - INFO - Training dataset size: 340. 
2025-07-12 16:15:39,401 - root - INFO - Evaluation dataset size: 76. 
2025-07-12 16:15:39,401 - root - INFO - OOD mask: 0 / 340. 
2025-07-12 16:15:39,401 - root - INFO - AL mask: 0 / 340. 
2025-07-12 16:15:39,401 - root - INFO - Evaluating on current checkpoint ckp_2. 
2025-07-12 16:15:39,401 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:15:39,402 - root - INFO - Subset length: 46
2025-07-12 16:15:39,824 - root - INFO - Eval on current training checkpoint ckp_2: Number of samples: 46, acc: 1.0000, balanced acc: 1.0000, loss: 1.0610. 
2025-07-12 16:15:39,824 - root - INFO - Evaluating on next checkpoint ckp_3. 
2025-07-12 16:15:40,960 - root - INFO - Number of samples: 76, acc: 0.8684, balanced acc: 0.8719, loss: 1.3882. 
2025-07-12 16:15:40,960 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:40,961 - root - INFO - Training on checkpoint ckp_4. 
2025-07-12 16:15:40,961 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:15:40,963 - root - INFO - Subset length: 99
2025-07-12 16:15:40,964 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:15:40,965 - root - INFO - Subset length: 57
2025-07-12 16:15:40,965 - root - INFO - Training dataset size: 99. 
2025-07-12 16:15:40,965 - root - INFO - Evaluation dataset size: 57. 
2025-07-12 16:15:40,965 - root - INFO - OOD mask: 0 / 99. 
2025-07-12 16:15:40,965 - root - INFO - AL mask: 0 / 99. 
2025-07-12 16:15:40,965 - root - INFO - Evaluating on current checkpoint ckp_3. 
2025-07-12 16:15:40,965 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:15:40,967 - root - INFO - Subset length: 76
2025-07-12 16:15:41,637 - root - INFO - Eval on current training checkpoint ckp_3: Number of samples: 76, acc: 0.8684, balanced acc: 0.8719, loss: 1.3882. 
2025-07-12 16:15:41,638 - root - INFO - Evaluating on next checkpoint ckp_4. 
2025-07-12 16:15:42,615 - root - INFO - Number of samples: 57, acc: 0.9123, balanced acc: 0.9106, loss: 1.2978. 
2025-07-12 16:15:42,615 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:42,616 - root - INFO - Training on checkpoint ckp_5. 
2025-07-12 16:15:42,616 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:15:42,619 - root - INFO - Subset length: 114
2025-07-12 16:15:42,619 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:15:42,620 - root - INFO - Subset length: 34
2025-07-12 16:15:42,620 - root - INFO - Training dataset size: 114. 
2025-07-12 16:15:42,620 - root - INFO - Evaluation dataset size: 34. 
2025-07-12 16:15:42,620 - root - INFO - OOD mask: 0 / 114. 
2025-07-12 16:15:42,620 - root - INFO - AL mask: 0 / 114. 
2025-07-12 16:15:42,620 - root - INFO - Evaluating on current checkpoint ckp_4. 
2025-07-12 16:15:42,620 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:15:42,621 - root - INFO - Subset length: 57
2025-07-12 16:15:43,173 - root - INFO - Eval on current training checkpoint ckp_4: Number of samples: 57, acc: 0.9123, balanced acc: 0.9106, loss: 1.2978. 
2025-07-12 16:15:43,173 - root - INFO - Evaluating on next checkpoint ckp_5. 
2025-07-12 16:15:43,981 - root - INFO - Number of samples: 34, acc: 1.0000, balanced acc: 1.0000, loss: 1.3249. 
2025-07-12 16:15:43,981 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:43,982 - root - INFO - Training on checkpoint ckp_6. 
2025-07-12 16:15:43,982 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:15:43,986 - root - INFO - Subset length: 161
2025-07-12 16:15:43,986 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:15:43,987 - root - INFO - Subset length: 44
2025-07-12 16:15:43,987 - root - INFO - Training dataset size: 161. 
2025-07-12 16:15:43,987 - root - INFO - Evaluation dataset size: 44. 
2025-07-12 16:15:43,987 - root - INFO - OOD mask: 0 / 161. 
2025-07-12 16:15:43,987 - root - INFO - AL mask: 0 / 161. 
2025-07-12 16:15:43,987 - root - INFO - Evaluating on current checkpoint ckp_5. 
2025-07-12 16:15:43,988 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:15:43,988 - root - INFO - Subset length: 34
2025-07-12 16:15:44,440 - root - INFO - Eval on current training checkpoint ckp_5: Number of samples: 34, acc: 1.0000, balanced acc: 1.0000, loss: 1.3249. 
2025-07-12 16:15:44,440 - root - INFO - Evaluating on next checkpoint ckp_6. 
2025-07-12 16:15:45,269 - root - INFO - Number of samples: 44, acc: 0.9773, balanced acc: 0.9750, loss: 1.2316. 
2025-07-12 16:15:45,269 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:45,271 - root - INFO - Training on checkpoint ckp_7. 
2025-07-12 16:15:45,271 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:15:45,275 - root - INFO - Subset length: 181
2025-07-12 16:15:45,275 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:15:45,276 - root - INFO - Subset length: 60
2025-07-12 16:15:45,276 - root - INFO - Training dataset size: 181. 
2025-07-12 16:15:45,276 - root - INFO - Evaluation dataset size: 60. 
2025-07-12 16:15:45,276 - root - INFO - OOD mask: 0 / 181. 
2025-07-12 16:15:45,276 - root - INFO - AL mask: 0 / 181. 
2025-07-12 16:15:45,276 - root - INFO - Evaluating on current checkpoint ckp_6. 
2025-07-12 16:15:45,277 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:15:45,277 - root - INFO - Subset length: 44
2025-07-12 16:15:45,737 - root - INFO - Eval on current training checkpoint ckp_6: Number of samples: 44, acc: 0.9773, balanced acc: 0.9750, loss: 1.2316. 
2025-07-12 16:15:45,738 - root - INFO - Evaluating on next checkpoint ckp_7. 
2025-07-12 16:15:46,866 - root - INFO - Number of samples: 60, acc: 0.9333, balanced acc: 0.9333, loss: 1.3154. 
2025-07-12 16:15:46,867 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
2025-07-12 16:15:46,868 - root - INFO - Training on checkpoint ckp_8. 
2025-07-12 16:15:46,868 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:15:46,871 - root - INFO - Subset length: 107
2025-07-12 16:15:46,871 - root - INFO - Gathering samples from checkpoints: ['ckp_8']
2025-07-12 16:15:46,873 - root - INFO - Subset length: 113
2025-07-12 16:15:46,873 - root - INFO - Training dataset size: 107. 
2025-07-12 16:15:46,873 - root - INFO - Evaluation dataset size: 113. 
2025-07-12 16:15:46,873 - root - INFO - OOD mask: 0 / 107. 
2025-07-12 16:15:46,873 - root - INFO - AL mask: 0 / 107. 
2025-07-12 16:15:46,874 - root - INFO - Evaluating on current checkpoint ckp_7. 
2025-07-12 16:15:46,874 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:15:46,875 - root - INFO - Subset length: 60
2025-07-12 16:15:47,474 - root - INFO - Eval on current training checkpoint ckp_7: Number of samples: 60, acc: 0.9333, balanced acc: 0.9333, loss: 1.3154. 
2025-07-12 16:15:47,474 - root - INFO - Evaluating on next checkpoint ckp_8. 
2025-07-12 16:15:50,109 - root - INFO - Number of samples: 113, acc: 0.7168, balanced acc: 0.7167, loss: 1.6787. 
2025-07-12 16:15:50,109 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_Q04/upper_bound/2025-07-12-15-53-20/bioclip2/full_text_head/2025-07-12-15-53-28/log. 
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          accuracy ‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÅ
wandb: balanced_accuracy ‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÅ
wandb: 
wandb: Run summary:
wandb:          accuracy 0.71681
wandb: balanced_accuracy 0.71667
wandb: 
wandb: üöÄ View run serengeti_serengeti_Q04 | upper_bound | 2025-07-12-15-53-20 | bioclip2 | full_text_head | 2025-07-12-15-53-28 at: https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/hh14rbkw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250712_155332-hh14rbkw/logs
2025-07-12 16:15:50,674 - root - INFO - Elapsed time: 1338.39 seconds. 
/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 16:15:57,978 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_C12/upper_bound/2025-07-12-16-15-53/bioclip2/full_text_head/2025-07-12-16-15-57/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_161558-b7lr14dj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_C12 | upper_bound | 2025-07-12-16-15-53 | bioclip2 | full_text_head | 2025-07-12-16-15-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/b7lr14dj
2025-07-12 16:15:58,857 - root - INFO - wandb logging is enabled.
2025-07-12 16:15:58,857 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_C12_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C12/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C12/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C12/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_C12/upper_bound/2025-07-12-16-15-53/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_C12/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_C12/upper_bound/2025-07-12-16-15-53/bioclip2/full_text_head/2025-07-12-16-15-57/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 16:15:58,874 - root - INFO - Using Bioclip-2 model. 
2025-07-12 16:15:58,874 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 16:16:00,796 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 16:16:03,720 - root - INFO - Pretraining classifier... 
2025-07-12 16:16:03,773 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 16:16:04,061 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 16:16:04,061 - root - INFO - Subset length: 7872
2025-07-12 16:16:04,064 - root - INFO - Pretrain dataset size: 7872. 
