/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 15:53:34,164 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_155334-jb6xxhj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_D07 | upper_bound | 2025-07-12-15-53-19 | bioclip2 | full_text_head | 2025-07-12-15-53-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/jb6xxhj8
2025-07-12 15:53:35,638 - root - INFO - wandb logging is enabled.
2025-07-12 15:53:35,639 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_D07_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_D07/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_D07/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_D07/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_D07/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 15:53:35,648 - root - INFO - Using Bioclip-2 model. 
2025-07-12 15:53:35,648 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 15:53:37,568 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 15:53:42,467 - root - INFO - Pretraining classifier... 
2025-07-12 15:53:42,481 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 15:53:42,511 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 15:53:42,511 - root - INFO - Subset length: 1549
2025-07-12 15:53:42,512 - root - INFO - Pretrain dataset size: 1549. 
2025-07-12 15:54:02,720 - root - INFO - Epoch 0, loss: 1.7864, acc: 0.9522, lr: 0.00002500. 
2025-07-12 15:54:22,481 - root - INFO - Epoch 1, loss: 1.7022, acc: 0.9858, lr: 0.00002494. 
2025-07-12 15:54:42,329 - root - INFO - Epoch 2, loss: 1.6720, acc: 0.9858, lr: 0.00002475. 
2025-07-12 15:55:02,164 - root - INFO - Epoch 3, loss: 1.6519, acc: 0.9729, lr: 0.00002445. 
2025-07-12 15:55:22,014 - root - INFO - Epoch 4, loss: 1.6210, acc: 0.9787, lr: 0.00002403. 
2025-07-12 15:55:41,793 - root - INFO - Epoch 5, loss: 1.5906, acc: 0.9877, lr: 0.00002349. 
2025-07-12 15:56:01,538 - root - INFO - Epoch 6, loss: 1.5601, acc: 0.9948, lr: 0.00002285. 
2025-07-12 15:56:21,332 - root - INFO - Epoch 7, loss: 1.5328, acc: 0.9994, lr: 0.00002211. 
2025-07-12 15:56:41,178 - root - INFO - Epoch 8, loss: 1.5072, acc: 1.0000, lr: 0.00002128. 
2025-07-12 15:57:00,999 - root - INFO - Epoch 9, loss: 1.4827, acc: 1.0000, lr: 0.00002036. 
2025-07-12 15:57:20,715 - root - INFO - Epoch 10, loss: 1.4596, acc: 1.0000, lr: 0.00001937. 
2025-07-12 15:57:40,488 - root - INFO - Epoch 11, loss: 1.4381, acc: 1.0000, lr: 0.00001833. 
2025-07-12 15:58:00,276 - root - INFO - Epoch 12, loss: 1.4177, acc: 1.0000, lr: 0.00001723. 
2025-07-12 15:58:20,115 - root - INFO - Epoch 13, loss: 1.3982, acc: 1.0000, lr: 0.00001609. 
2025-07-12 15:58:39,867 - root - INFO - Epoch 14, loss: 1.3805, acc: 1.0000, lr: 0.00001493. 
2025-07-12 15:58:59,606 - root - INFO - Epoch 15, loss: 1.3639, acc: 1.0000, lr: 0.00001375. 
2025-07-12 15:59:19,546 - root - INFO - Epoch 16, loss: 1.3497, acc: 1.0000, lr: 0.00001257. 
2025-07-12 15:59:39,298 - root - INFO - Epoch 17, loss: 1.3362, acc: 1.0000, lr: 0.00001141. 
2025-07-12 15:59:59,259 - root - INFO - Epoch 18, loss: 1.3241, acc: 1.0000, lr: 0.00001027. 
2025-07-12 16:00:19,106 - root - INFO - Epoch 19, loss: 1.3129, acc: 1.0000, lr: 0.00000917. 
2025-07-12 16:00:39,023 - root - INFO - Epoch 20, loss: 1.3032, acc: 1.0000, lr: 0.00000813. 
2025-07-12 16:00:58,914 - root - INFO - Epoch 21, loss: 1.2949, acc: 1.0000, lr: 0.00000714. 
2025-07-12 16:01:18,747 - root - INFO - Epoch 22, loss: 1.2875, acc: 1.0000, lr: 0.00000622. 
2025-07-12 16:01:38,609 - root - INFO - Epoch 23, loss: 1.2815, acc: 1.0000, lr: 0.00000539. 
2025-07-12 16:01:58,371 - root - INFO - Epoch 24, loss: 1.2763, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:02:18,149 - root - INFO - Epoch 25, loss: 1.2711, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:02:38,014 - root - INFO - Epoch 26, loss: 1.2673, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:02:57,711 - root - INFO - Epoch 27, loss: 1.2637, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:03:17,486 - root - INFO - Epoch 28, loss: 1.2607, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:03:37,295 - root - INFO - Epoch 29, loss: 1.2581, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:03:57,063 - root - INFO - Epoch 30, loss: 1.2554, acc: 1.0000, lr: 0.00000250. 
2025-07-12 16:04:16,827 - root - INFO - Epoch 31, loss: 1.2525, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:04:36,558 - root - INFO - Epoch 32, loss: 1.2500, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:04:56,394 - root - INFO - Epoch 33, loss: 1.2463, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:05:16,297 - root - INFO - Epoch 34, loss: 1.2429, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:05:36,082 - root - INFO - Epoch 35, loss: 1.2398, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:05:55,845 - root - INFO - Epoch 36, loss: 1.2343, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:06:15,682 - root - INFO - Epoch 37, loss: 1.2287, acc: 1.0000, lr: 0.00000539. 
2025-07-12 16:06:35,491 - root - INFO - Epoch 38, loss: 1.2236, acc: 1.0000, lr: 0.00000622. 
2025-07-12 16:06:55,302 - root - INFO - Epoch 39, loss: 1.2161, acc: 1.0000, lr: 0.00000714. 
2025-07-12 16:07:15,013 - root - INFO - Epoch 40, loss: 1.2086, acc: 1.0000, lr: 0.00000813. 
2025-07-12 16:07:34,884 - root - INFO - Epoch 41, loss: 1.1987, acc: 1.0000, lr: 0.00000917. 
2025-07-12 16:07:54,730 - root - INFO - Epoch 42, loss: 1.1897, acc: 1.0000, lr: 0.00001027. 
2025-07-12 16:08:14,510 - root - INFO - Epoch 43, loss: 1.1777, acc: 1.0000, lr: 0.00001141. 
2025-07-12 16:08:34,289 - root - INFO - Epoch 44, loss: 1.1655, acc: 1.0000, lr: 0.00001257. 
2025-07-12 16:08:54,153 - root - INFO - Epoch 45, loss: 1.1519, acc: 1.0000, lr: 0.00001375. 
2025-07-12 16:09:13,919 - root - INFO - Epoch 46, loss: 1.1372, acc: 1.0000, lr: 0.00001493. 
2025-07-12 16:09:33,669 - root - INFO - Epoch 47, loss: 1.1228, acc: 1.0000, lr: 0.00001609. 
2025-07-12 16:09:53,470 - root - INFO - Epoch 48, loss: 1.1057, acc: 1.0000, lr: 0.00001723. 
2025-07-12 16:10:13,193 - root - INFO - Epoch 49, loss: 1.0891, acc: 1.0000, lr: 0.00001833. 
2025-07-12 16:10:33,007 - root - INFO - Epoch 50, loss: 1.0715, acc: 1.0000, lr: 0.00001938. 
2025-07-12 16:10:52,983 - root - INFO - Epoch 51, loss: 1.0521, acc: 1.0000, lr: 0.00002036. 
2025-07-12 16:11:12,689 - root - INFO - Epoch 52, loss: 1.0331, acc: 1.0000, lr: 0.00002128. 
2025-07-12 16:11:32,451 - root - INFO - Epoch 53, loss: 1.0129, acc: 1.0000, lr: 0.00002211. 
2025-07-12 16:11:52,148 - root - INFO - Epoch 54, loss: 0.9942, acc: 1.0000, lr: 0.00002285. 
2025-07-12 16:12:12,022 - root - INFO - Epoch 55, loss: 0.9742, acc: 1.0000, lr: 0.00002349. 
2025-07-12 16:12:31,875 - root - INFO - Epoch 56, loss: 0.9534, acc: 1.0000, lr: 0.00002403. 
2025-07-12 16:12:51,615 - root - INFO - Epoch 57, loss: 0.9318, acc: 1.0000, lr: 0.00002445. 
2025-07-12 16:13:11,573 - root - INFO - Epoch 58, loss: 0.9123, acc: 1.0000, lr: 0.00002475. 
2025-07-12 16:13:31,395 - root - INFO - Epoch 59, loss: 0.8914, acc: 1.0000, lr: 0.00002494. 
2025-07-12 16:13:31,414 - root - INFO - Checkpoint list, length: 8: 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_1 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_2 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_3 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_4 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_5 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_6 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_7 
2025-07-12 16:13:31,414 - root - INFO - 	ckp_8 
2025-07-12 16:13:31,427 - root - INFO - Training on checkpoint ckp_1. 
2025-07-12 16:13:31,427 - root - INFO - Subset length: 0
2025-07-12 16:13:31,427 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:13:31,428 - root - INFO - Subset length: 42
2025-07-12 16:13:31,428 - root - INFO - Training dataset size: 0. 
2025-07-12 16:13:31,428 - root - INFO - Evaluation dataset size: 42. 
2025-07-12 16:13:31,428 - root - INFO - OOD mask: 0 / 0. 
2025-07-12 16:13:31,428 - root - INFO - AL mask: 0 / 0. 
2025-07-12 16:13:31,429 - root - INFO - Evaluating on next checkpoint ckp_1. 
2025-07-12 16:13:32,102 - root - INFO - Number of samples: 42, acc: 0.7619, balanced acc: 0.7500, loss: 1.3140. 
2025-07-12 16:13:32,102 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:32,105 - root - INFO - Training on checkpoint ckp_2. 
2025-07-12 16:13:32,105 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:13:32,110 - root - INFO - Subset length: 242
2025-07-12 16:13:32,110 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:13:32,111 - root - INFO - Subset length: 44
2025-07-12 16:13:32,111 - root - INFO - Training dataset size: 242. 
2025-07-12 16:13:32,111 - root - INFO - Evaluation dataset size: 44. 
2025-07-12 16:13:32,112 - root - INFO - OOD mask: 0 / 242. 
2025-07-12 16:13:32,112 - root - INFO - AL mask: 0 / 242. 
2025-07-12 16:13:32,112 - root - INFO - Evaluating on current checkpoint ckp_1. 
2025-07-12 16:13:32,112 - root - INFO - Gathering samples from checkpoints: ['ckp_1']
2025-07-12 16:13:32,113 - root - INFO - Subset length: 42
2025-07-12 16:13:32,508 - root - INFO - Eval on current training checkpoint ckp_1: Number of samples: 42, acc: 0.7619, balanced acc: 0.7500, loss: 1.3140. 
2025-07-12 16:13:32,508 - root - INFO - Evaluating on next checkpoint ckp_2. 
2025-07-12 16:13:33,113 - root - INFO - Number of samples: 44, acc: 1.0000, balanced acc: 1.0000, loss: 1.0636. 
2025-07-12 16:13:33,113 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:33,114 - root - INFO - Training on checkpoint ckp_3. 
2025-07-12 16:13:33,115 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:13:33,117 - root - INFO - Subset length: 129
2025-07-12 16:13:33,118 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:13:33,119 - root - INFO - Subset length: 44
2025-07-12 16:13:33,119 - root - INFO - Training dataset size: 129. 
2025-07-12 16:13:33,119 - root - INFO - Evaluation dataset size: 44. 
2025-07-12 16:13:33,119 - root - INFO - OOD mask: 0 / 129. 
2025-07-12 16:13:33,119 - root - INFO - AL mask: 0 / 129. 
2025-07-12 16:13:33,119 - root - INFO - Evaluating on current checkpoint ckp_2. 
2025-07-12 16:13:33,119 - root - INFO - Gathering samples from checkpoints: ['ckp_2']
2025-07-12 16:13:33,120 - root - INFO - Subset length: 44
2025-07-12 16:13:33,496 - root - INFO - Eval on current training checkpoint ckp_2: Number of samples: 44, acc: 1.0000, balanced acc: 1.0000, loss: 1.0636. 
2025-07-12 16:13:33,496 - root - INFO - Evaluating on next checkpoint ckp_3. 
2025-07-12 16:13:34,190 - root - INFO - Number of samples: 44, acc: 0.9318, balanced acc: 0.9250, loss: 1.1292. 
2025-07-12 16:13:34,191 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:34,193 - root - INFO - Training on checkpoint ckp_4. 
2025-07-12 16:13:34,193 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:13:34,196 - root - INFO - Subset length: 138
2025-07-12 16:13:34,196 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:13:34,197 - root - INFO - Subset length: 32
2025-07-12 16:13:34,197 - root - INFO - Training dataset size: 138. 
2025-07-12 16:13:34,197 - root - INFO - Evaluation dataset size: 32. 
2025-07-12 16:13:34,197 - root - INFO - OOD mask: 0 / 138. 
2025-07-12 16:13:34,197 - root - INFO - AL mask: 0 / 138. 
2025-07-12 16:13:34,197 - root - INFO - Evaluating on current checkpoint ckp_3. 
2025-07-12 16:13:34,197 - root - INFO - Gathering samples from checkpoints: ['ckp_3']
2025-07-12 16:13:34,198 - root - INFO - Subset length: 44
2025-07-12 16:13:34,611 - root - INFO - Eval on current training checkpoint ckp_3: Number of samples: 44, acc: 0.9318, balanced acc: 0.9250, loss: 1.1292. 
2025-07-12 16:13:34,612 - root - INFO - Evaluating on next checkpoint ckp_4. 
2025-07-12 16:13:35,258 - root - INFO - Number of samples: 32, acc: 1.0000, balanced acc: 1.0000, loss: 0.9468. 
2025-07-12 16:13:35,259 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:35,259 - root - INFO - Training on checkpoint ckp_5. 
2025-07-12 16:13:35,259 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:13:35,265 - root - INFO - Subset length: 245
2025-07-12 16:13:35,265 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:13:35,267 - root - INFO - Subset length: 54
2025-07-12 16:13:35,267 - root - INFO - Training dataset size: 245. 
2025-07-12 16:13:35,267 - root - INFO - Evaluation dataset size: 54. 
2025-07-12 16:13:35,267 - root - INFO - OOD mask: 0 / 245. 
2025-07-12 16:13:35,267 - root - INFO - AL mask: 0 / 245. 
2025-07-12 16:13:35,267 - root - INFO - Evaluating on current checkpoint ckp_4. 
2025-07-12 16:13:35,267 - root - INFO - Gathering samples from checkpoints: ['ckp_4']
2025-07-12 16:13:35,268 - root - INFO - Subset length: 32
2025-07-12 16:13:35,628 - root - INFO - Eval on current training checkpoint ckp_4: Number of samples: 32, acc: 1.0000, balanced acc: 1.0000, loss: 0.9468. 
2025-07-12 16:13:35,628 - root - INFO - Evaluating on next checkpoint ckp_5. 
2025-07-12 16:13:36,278 - root - INFO - Number of samples: 54, acc: 0.9630, balanced acc: 0.9600, loss: 1.0220. 
2025-07-12 16:13:36,278 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:36,279 - root - INFO - Training on checkpoint ckp_6. 
2025-07-12 16:13:36,279 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:13:36,282 - root - INFO - Subset length: 116
2025-07-12 16:13:36,282 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:13:36,283 - root - INFO - Subset length: 44
2025-07-12 16:13:36,283 - root - INFO - Training dataset size: 116. 
2025-07-12 16:13:36,283 - root - INFO - Evaluation dataset size: 44. 
2025-07-12 16:13:36,284 - root - INFO - OOD mask: 0 / 116. 
2025-07-12 16:13:36,284 - root - INFO - AL mask: 0 / 116. 
2025-07-12 16:13:36,284 - root - INFO - Evaluating on current checkpoint ckp_5. 
2025-07-12 16:13:36,284 - root - INFO - Gathering samples from checkpoints: ['ckp_5']
2025-07-12 16:13:36,285 - root - INFO - Subset length: 54
2025-07-12 16:13:36,693 - root - INFO - Eval on current training checkpoint ckp_5: Number of samples: 54, acc: 0.9630, balanced acc: 0.9600, loss: 1.0220. 
2025-07-12 16:13:36,693 - root - INFO - Evaluating on next checkpoint ckp_6. 
2025-07-12 16:13:37,300 - root - INFO - Number of samples: 44, acc: 1.0000, balanced acc: 1.0000, loss: 0.8983. 
2025-07-12 16:13:37,301 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:37,302 - root - INFO - Training on checkpoint ckp_7. 
2025-07-12 16:13:37,302 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:13:37,305 - root - INFO - Subset length: 126
2025-07-12 16:13:37,305 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:13:37,306 - root - INFO - Subset length: 32
2025-07-12 16:13:37,306 - root - INFO - Training dataset size: 126. 
2025-07-12 16:13:37,306 - root - INFO - Evaluation dataset size: 32. 
2025-07-12 16:13:37,306 - root - INFO - OOD mask: 0 / 126. 
2025-07-12 16:13:37,306 - root - INFO - AL mask: 0 / 126. 
2025-07-12 16:13:37,306 - root - INFO - Evaluating on current checkpoint ckp_6. 
2025-07-12 16:13:37,306 - root - INFO - Gathering samples from checkpoints: ['ckp_6']
2025-07-12 16:13:37,307 - root - INFO - Subset length: 44
2025-07-12 16:13:37,674 - root - INFO - Eval on current training checkpoint ckp_6: Number of samples: 44, acc: 1.0000, balanced acc: 1.0000, loss: 0.8983. 
2025-07-12 16:13:37,675 - root - INFO - Evaluating on next checkpoint ckp_7. 
2025-07-12 16:13:38,368 - root - INFO - Number of samples: 32, acc: 1.0000, balanced acc: 1.0000, loss: 1.0419. 
2025-07-12 16:13:38,368 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
2025-07-12 16:13:38,369 - root - INFO - Training on checkpoint ckp_8. 
2025-07-12 16:13:38,369 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:13:38,372 - root - INFO - Subset length: 116
2025-07-12 16:13:38,372 - root - INFO - Gathering samples from checkpoints: ['ckp_8']
2025-07-12 16:13:38,373 - root - INFO - Subset length: 65
2025-07-12 16:13:38,374 - root - INFO - Training dataset size: 116. 
2025-07-12 16:13:38,374 - root - INFO - Evaluation dataset size: 65. 
2025-07-12 16:13:38,374 - root - INFO - OOD mask: 0 / 116. 
2025-07-12 16:13:38,374 - root - INFO - AL mask: 0 / 116. 
2025-07-12 16:13:38,374 - root - INFO - Evaluating on current checkpoint ckp_7. 
2025-07-12 16:13:38,374 - root - INFO - Gathering samples from checkpoints: ['ckp_7']
2025-07-12 16:13:38,375 - root - INFO - Subset length: 32
2025-07-12 16:13:38,739 - root - INFO - Eval on current training checkpoint ckp_7: Number of samples: 32, acc: 1.0000, balanced acc: 1.0000, loss: 1.0419. 
2025-07-12 16:13:38,740 - root - INFO - Evaluating on next checkpoint ckp_8. 
2025-07-12 16:13:40,122 - root - INFO - Number of samples: 65, acc: 0.7692, balanced acc: 0.7778, loss: 1.3991. 
2025-07-12 16:13:40,123 - root - INFO - Saving predictions to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_D07/upper_bound/2025-07-12-15-53-19/bioclip2/full_text_head/2025-07-12-15-53-34/log. 
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          accuracy ‚ñÅ‚ñà‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÅ
wandb: balanced_accuracy ‚ñÅ‚ñà‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÇ
wandb: 
wandb: Run summary:
wandb:          accuracy 0.76923
wandb: balanced_accuracy 0.77778
wandb: 
wandb: üöÄ View run serengeti_serengeti_D07 | upper_bound | 2025-07-12-15-53-19 | bioclip2 | full_text_head | 2025-07-12-15-53-34 at: https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/jb6xxhj8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250712_155334-jb6xxhj8/logs
2025-07-12 16:13:40,657 - root - INFO - Elapsed time: 1206.49 seconds. 
/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 16:13:47,809 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_S08/upper_bound/2025-07-12-16-13-42/bioclip2/full_text_head/2025-07-12-16-13-47/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_161347-rlvtcsix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_S08 | upper_bound | 2025-07-12-16-13-42 | bioclip2 | full_text_head | 2025-07-12-16-13-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/rlvtcsix
2025-07-12 16:13:48,744 - root - INFO - wandb logging is enabled.
2025-07-12 16:13:48,745 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_S08_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_S08/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_S08/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_S08/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_S08/upper_bound/2025-07-12-16-13-42/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_S08/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_S08/upper_bound/2025-07-12-16-13-42/bioclip2/full_text_head/2025-07-12-16-13-47/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 16:13:48,750 - root - INFO - Using Bioclip-2 model. 
2025-07-12 16:13:48,750 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 16:13:50,681 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 16:13:53,721 - root - INFO - Pretraining classifier... 
2025-07-12 16:13:53,733 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 16:13:53,757 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 16:13:53,757 - root - INFO - Subset length: 1171
2025-07-12 16:13:53,757 - root - INFO - Pretrain dataset size: 1171. 
2025-07-12 16:14:09,246 - root - INFO - Epoch 0, loss: 2.1043, acc: 0.8873, lr: 0.00002500. 
2025-07-12 16:14:24,471 - root - INFO - Epoch 1, loss: 2.0030, acc: 0.9658, lr: 0.00002494. 
2025-07-12 16:14:39,881 - root - INFO - Epoch 2, loss: 1.9677, acc: 0.9855, lr: 0.00002475. 
2025-07-12 16:14:55,048 - root - INFO - Epoch 3, loss: 1.9396, acc: 0.9966, lr: 0.00002445. 
2025-07-12 16:15:10,309 - root - INFO - Epoch 4, loss: 1.9165, acc: 1.0000, lr: 0.00002403. 
2025-07-12 16:15:25,457 - root - INFO - Epoch 5, loss: 1.8958, acc: 0.9974, lr: 0.00002349. 
2025-07-12 16:15:40,775 - root - INFO - Epoch 6, loss: 1.8743, acc: 1.0000, lr: 0.00002285. 
2025-07-12 16:15:56,023 - root - INFO - Epoch 7, loss: 1.8539, acc: 1.0000, lr: 0.00002211. 
2025-07-12 16:16:11,299 - root - INFO - Epoch 8, loss: 1.8341, acc: 1.0000, lr: 0.00002128. 
2025-07-12 16:16:26,651 - root - INFO - Epoch 9, loss: 1.8152, acc: 1.0000, lr: 0.00002036. 
