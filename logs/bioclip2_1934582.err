/users/PAS2099/mino/miniconda3/envs/ICICLE/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-12 15:53:19,246 - root - INFO - Saving to /fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_I12/upper_bound/2025-07-12-15-53-08/bioclip2/full_text_head/2025-07-12-15-53-19/log. 
wandb: Currently logged in as: minodaze (minodaze-the-ohio-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /users/PAS2099/mino/ICICLE/wandb/run-20250712_155319-9hrgw2ar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serengeti_serengeti_I12 | upper_bound | 2025-07-12-15-53-08 | bioclip2 | full_text_head | 2025-07-12-15-53-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark
wandb: üöÄ View run at https://wandb.ai/minodaze-the-ohio-state-university/ICICLE-Benchmark/runs/9hrgw2ar
2025-07-12 15:53:20,629 - root - INFO - wandb logging is enabled.
2025-07-12 15:53:20,629 - root - INFO - {'accu_eval': False,
 'adapter_bottleneck': 64,
 'adapter_init': 'lora_kaiming',
 'adapter_scaler': 0.1,
 'al_config': {'method': 'none'},
 'attention_index': None,
 'attention_type': 'full',
 'bitfit': False,
 'block_index': None,
 'c': '/fs/scratch/PAS2099/mino/ICICLE/configs/generated_common/serengeti_serengeti_I12_upper_bound.yaml',
 'cl_config': {'method': 'none'},
 'common_config': {'model': 'bioclip2', 'train_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_I12/30/train.json', 'eval_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_I12/30/test.json', 'all_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_I12/30/train-all.json', 'train_batch_size': 32, 'eval_batch_size': 512, 'optimizer_name': 'AdamW', 'optimizer_params': {'lr': 2.5e-05, 'weight_decay': 0.0001}, 'chop_head': False, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 30, 'eta_min': 2.5e-06}},
 'convpass_bottleneck': 8,
 'convpass_init': 'lora_xavier',
 'convpass_scaler': 10,
 'convpass_xavier_init': False,
 'debug': False,
 'device': 'cuda',
 'difffit': False,
 'drop_path_rate': 0.0,
 'eval_only': False,
 'eval_per_epoch': False,
 'fact_dim': 8,
 'fact_scaler': 1.0,
 'fact_type': None,
 'ft_attn_ln': 'before',
 'ft_attn_mode': 'parallel',
 'ft_attn_module': None,
 'ft_mlp_ln': 'before',
 'ft_mlp_mode': 'parallel',
 'ft_mlp_module': None,
 'full': True,
 'generalization_test': 'a',
 'gpu_id': None,
 'gpu_memory_monitor': False,
 'interpolation_alpha': 0.5,
 'interpolation_head': False,
 'interpolation_model': False,
 'is_save': False,
 'label_type': 'common',
 'ln': False,
 'log_path': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_I12/upper_bound/2025-07-12-15-53-08/',
 'lora_bottleneck': 0,
 'merge_factor': 1,
 'mlp_index': None,
 'mlp_type': 'full',
 'module_name': 'upper_bound',
 'no_gpu_monitor_colors': False,
 'ood_config': {'method': 'none'},
 'pretrain_config': {'pretrain': True, 'pretrain_data_config_path': '/fs/scratch/PAS2099/camera-trap-benchmark/serengeti/serengeti_I12/30/train-all.json', 'epochs': 60, 'loss_type': 'ce'},
 'pretrained_weights': 'bioclip2',
 'repadapter_bottleneck': 8,
 'repadapter_group': 2,
 'repadapter_init': 'lora_xavier',
 'repadapter_scaler': 1,
 'save_dir': '/fs/scratch/PAS2099/mino/ICICLE/log_auto/pipeline/serengeti_serengeti_I12/upper_bound/2025-07-12-15-53-08/bioclip2/full_text_head/2025-07-12-15-53-19/log',
 'seed': 9527,
 'ssf': False,
 'text': 'head',
 'text_template': 'openai',
 'vpt_dropout': 0.1,
 'vpt_layer': None,
 'vpt_mode': None,
 'vpt_num': 10,
 'vqt_dropout': 0.1,
 'vqt_num': 0,
 'wandb': True}
2025-07-12 15:53:20,640 - root - INFO - Using Bioclip-2 model. 
2025-07-12 15:53:20,640 - root - INFO - Loaded ViT-L-14 model config.
2025-07-12 15:53:22,554 - root - INFO - Loading pretrained ViT-L-14 weights (pretrained_weights/bioclip-2/open_clip_pytorch_model.bin).
2025-07-12 15:53:28,185 - root - INFO - Pretraining classifier... 
2025-07-12 15:53:28,204 - root - INFO - Gathering samples from checkpoints: ['ckp_-1', 'ckp_1']
2025-07-12 15:53:28,248 - root - INFO - Checkpoint ckp_1 not found
2025-07-12 15:53:28,248 - root - INFO - Subset length: 2296
2025-07-12 15:53:28,249 - root - INFO - Pretrain dataset size: 2296. 
2025-07-12 15:53:57,952 - root - INFO - Epoch 0, loss: 2.1166, acc: 0.9547, lr: 0.00002500. 
2025-07-12 15:54:27,304 - root - INFO - Epoch 1, loss: 2.0241, acc: 0.9839, lr: 0.00002494. 
2025-07-12 15:54:56,642 - root - INFO - Epoch 2, loss: 1.9705, acc: 0.9926, lr: 0.00002475. 
2025-07-12 15:55:25,980 - root - INFO - Epoch 3, loss: 1.9229, acc: 0.9939, lr: 0.00002445. 
2025-07-12 15:55:55,421 - root - INFO - Epoch 4, loss: 1.8933, acc: 0.9686, lr: 0.00002403. 
2025-07-12 15:56:24,785 - root - INFO - Epoch 5, loss: 1.8334, acc: 0.9917, lr: 0.00002349. 
2025-07-12 15:56:54,120 - root - INFO - Epoch 6, loss: 1.7826, acc: 0.9983, lr: 0.00002285. 
2025-07-12 15:57:23,381 - root - INFO - Epoch 7, loss: 1.7496, acc: 0.9830, lr: 0.00002211. 
2025-07-12 15:57:52,749 - root - INFO - Epoch 8, loss: 1.7016, acc: 0.9909, lr: 0.00002128. 
2025-07-12 15:58:22,007 - root - INFO - Epoch 9, loss: 1.6594, acc: 0.9952, lr: 0.00002036. 
2025-07-12 15:58:51,343 - root - INFO - Epoch 10, loss: 1.6215, acc: 0.9956, lr: 0.00001937. 
2025-07-12 15:59:20,679 - root - INFO - Epoch 11, loss: 1.5877, acc: 0.9943, lr: 0.00001833. 
2025-07-12 15:59:50,003 - root - INFO - Epoch 12, loss: 1.5504, acc: 0.9996, lr: 0.00001723. 
2025-07-12 16:00:19,264 - root - INFO - Epoch 13, loss: 1.5198, acc: 1.0000, lr: 0.00001609. 
2025-07-12 16:00:48,682 - root - INFO - Epoch 14, loss: 1.4919, acc: 1.0000, lr: 0.00001493. 
2025-07-12 16:01:18,015 - root - INFO - Epoch 15, loss: 1.4660, acc: 1.0000, lr: 0.00001375. 
2025-07-12 16:01:47,427 - root - INFO - Epoch 16, loss: 1.4433, acc: 1.0000, lr: 0.00001257. 
2025-07-12 16:02:16,758 - root - INFO - Epoch 17, loss: 1.4225, acc: 1.0000, lr: 0.00001141. 
2025-07-12 16:02:46,127 - root - INFO - Epoch 18, loss: 1.4042, acc: 1.0000, lr: 0.00001027. 
2025-07-12 16:03:15,439 - root - INFO - Epoch 19, loss: 1.3876, acc: 1.0000, lr: 0.00000917. 
2025-07-12 16:03:44,809 - root - INFO - Epoch 20, loss: 1.3728, acc: 1.0000, lr: 0.00000813. 
2025-07-12 16:04:14,042 - root - INFO - Epoch 21, loss: 1.3603, acc: 1.0000, lr: 0.00000714. 
2025-07-12 16:04:43,407 - root - INFO - Epoch 22, loss: 1.3496, acc: 1.0000, lr: 0.00000622. 
2025-07-12 16:05:12,794 - root - INFO - Epoch 23, loss: 1.3399, acc: 1.0000, lr: 0.00000539. 
2025-07-12 16:05:42,078 - root - INFO - Epoch 24, loss: 1.3316, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:06:11,378 - root - INFO - Epoch 25, loss: 1.3244, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:06:40,722 - root - INFO - Epoch 26, loss: 1.3188, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:07:10,008 - root - INFO - Epoch 27, loss: 1.3133, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:07:39,321 - root - INFO - Epoch 28, loss: 1.3086, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:08:08,632 - root - INFO - Epoch 29, loss: 1.3040, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:08:37,961 - root - INFO - Epoch 30, loss: 1.3000, acc: 1.0000, lr: 0.00000250. 
2025-07-12 16:09:07,327 - root - INFO - Epoch 31, loss: 1.2964, acc: 1.0000, lr: 0.00000256. 
2025-07-12 16:09:36,573 - root - INFO - Epoch 32, loss: 1.2915, acc: 1.0000, lr: 0.00000275. 
2025-07-12 16:10:05,906 - root - INFO - Epoch 33, loss: 1.2869, acc: 1.0000, lr: 0.00000305. 
2025-07-12 16:10:35,226 - root - INFO - Epoch 34, loss: 1.2817, acc: 1.0000, lr: 0.00000347. 
2025-07-12 16:11:04,568 - root - INFO - Epoch 35, loss: 1.2758, acc: 1.0000, lr: 0.00000401. 
2025-07-12 16:11:33,852 - root - INFO - Epoch 36, loss: 1.2688, acc: 1.0000, lr: 0.00000465. 
2025-07-12 16:12:03,175 - root - INFO - Epoch 37, loss: 1.2610, acc: 1.0000, lr: 0.00000539. 
2025-07-12 16:12:32,687 - root - INFO - Epoch 38, loss: 1.2520, acc: 1.0000, lr: 0.00000622. 
2025-07-12 16:13:02,118 - root - INFO - Epoch 39, loss: 1.2411, acc: 1.0000, lr: 0.00000714. 
2025-07-12 16:13:31,496 - root - INFO - Epoch 40, loss: 1.2294, acc: 1.0000, lr: 0.00000813. 
2025-07-12 16:14:00,893 - root - INFO - Epoch 41, loss: 1.2163, acc: 1.0000, lr: 0.00000917. 
2025-07-12 16:14:30,167 - root - INFO - Epoch 42, loss: 1.2012, acc: 1.0000, lr: 0.00001027. 
2025-07-12 16:14:59,515 - root - INFO - Epoch 43, loss: 1.1852, acc: 1.0000, lr: 0.00001141. 
2025-07-12 16:15:28,747 - root - INFO - Epoch 44, loss: 1.1674, acc: 1.0000, lr: 0.00001257. 
2025-07-12 16:15:58,089 - root - INFO - Epoch 45, loss: 1.1484, acc: 1.0000, lr: 0.00001375. 
2025-07-12 16:16:27,307 - root - INFO - Epoch 46, loss: 1.1281, acc: 1.0000, lr: 0.00001493. 
